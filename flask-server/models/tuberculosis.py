# -*- coding: utf-8 -*-
"""Tuberculosis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15TCI8uHh7YHgMCd-8NOIKe4KLuPiLWRx
"""

# Import necessary libraries
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix
from google.colab import files
import cv2
from IPython.display import display, Image
import seaborn as sns
from google.colab import drive

# Mount Google Drive to access your dataset
drive.mount('/content/drive')

# Set the path to your dataset directory
# Update this path to match your actual directory structure in Google Drive
base_dir = '/content/drive/MyDrive/TB_Chest_Radiography_Database'  # Update this path

# Function to automatically detect and set up class folders
def setup_dataset_paths(base_dir):
    class_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]
    class_counts = {}

    print("Detected classes:")
    for class_dir in class_dirs:
        path = os.path.join(base_dir, class_dir)
        num_images = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])
        class_counts[class_dir] = num_images
        print(f"- {class_dir}: {num_images} images")

    return class_dirs, class_counts

class_dirs, class_counts = setup_dataset_paths(base_dir)
num_classes = len(class_dirs)

# Image parameters
img_height, img_width = 224, 224
batch_size = 32

# Create data generators with augmentation for training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,  # 20% for validation
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Only rescaling for validation data
validation_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# Load training data
train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

# Load validation data
validation_generator = validation_datagen.flow_from_directory(
    base_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

# Get class indices
class_indices = train_generator.class_indices
print("Class indices:", class_indices)

# Handle class imbalance
# Calculate class weights based on the counts we gathered
total_samples = sum(class_counts.values())
class_weights = {i: total_samples / (len(class_counts) * count)
                 for i, (cls, count) in enumerate(class_counts.items())}
print("Class weights:", class_weights)

# Build the CNN model
def build_model(input_shape=(img_height, img_width, 3), num_classes=num_classes):
    model = Sequential([
        # First convolutional block
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        BatchNormalization(),
        Conv2D(32, (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2, 2),
        Dropout(0.25),

        # Second convolutional block
        Conv2D(64, (3, 3), activation='relu'),
        BatchNormalization(),
        Conv2D(64, (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2, 2),
        Dropout(0.25),

        # Third convolutional block
        Conv2D(128, (3, 3), activation='relu'),
        BatchNormalization(),
        Conv2D(128, (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2, 2),
        Dropout(0.25),

        # Flatten and dense layers
        Flatten(),
        Dense(512, activation='relu'),
        BatchNormalization(),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

    # Compile the model
    model.compile(
        optimizer=Adam(learning_rate=0.0001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

# Create the model
model = build_model()
model.summary()

# Set up callbacks for training
checkpoint = ModelCheckpoint(
    'tb_detection_model_best.h5',
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_accuracy',
    patience=10,
    restore_best_weights=True,
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,
    patience=5,
    min_lr=1e-6,
    verbose=1
)

callbacks = [checkpoint, early_stopping, reduce_lr]

# Train the model
epochs = 50
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size,
    callbacks=callbacks,
    class_weight=class_weights
)

# Save the model
model.save('tb_detection_model_final.h5')

# Plot training history
plt.figure(figsize=(12, 4))

# Plot training & validation accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='lower right')

# Plot training & validation loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')

plt.tight_layout()
plt.show()

# Evaluate the model on the validation set
validation_generator.reset()
Y_pred = model.predict(validation_generator)
y_pred = np.argmax(Y_pred, axis=1)
print('Confusion Matrix')
conf_mat = confusion_matrix(validation_generator.classes, y_pred)
print(conf_mat)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',
            xticklabels=list(class_indices.keys()),
            yticklabels=list(class_indices.keys()))
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

print('Classification Report')
class_names = list(class_indices.keys())
print(classification_report(validation_generator.classes, y_pred, target_names=class_names))

# Function to predict a single image
def predict_image(model, image_path, class_indices):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (img_height, img_width))
    img = img / 255.0
    img = np.expand_dims(img, axis=0)

    prediction = model.predict(img)
    predicted_class = np.argmax(prediction, axis=1)[0]

    # Get class label from indices
    class_labels = {v: k for k, v in class_indices.items()}
    predicted_label = class_labels[predicted_class]
    confidence = prediction[0][predicted_class] * 100

    return predicted_label, confidence, prediction[0]

# Upload and predict functionality
def upload_and_predict():
    uploaded = files.upload()

    for filename in uploaded.keys():
        image_path = filename

        # Display the uploaded image
        display(Image(filename=image_path, width=300))

        # Make prediction
        predicted_label, confidence, all_probs = predict_image(model, image_path, class_indices)

        print(f"Prediction: {predicted_label}")
        print(f"Confidence: {confidence:.2f}%")

        # Display all class probabilities
        print("\nClass probabilities:")
        class_labels = {v: k for k, v in class_indices.items()}
        for i, prob in enumerate(all_probs):
            print(f"{class_labels[i]}: {prob*100:.2f}%")

# Call the upload function
print("\n=== Upload an image for TB detection ===")
upload_and_predict()